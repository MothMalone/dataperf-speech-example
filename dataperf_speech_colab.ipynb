{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We start by cloning our example selection algorithm repository and installing some additional dependencies not preinstalled in Colab environments:"
      ],
      "metadata": {
        "id": "E5uSni11iDCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fire"
      ],
      "metadata": {
        "id": "LErPly0cbAsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H3n3AbLSjmSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziMgWteSaZcD"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/harvard-edge/dataperf-speech-example/\n",
        "import sys\n",
        "sys.path.append(\"/content/dataperf-speech-example/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO\n",
        "\n",
        "Download the dataperf data from an MLCommons bucket"
      ],
      "metadata": {
        "id": "LlJkO4lSjqXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in [\"en\", \"id\", \"pt\"]:\n",
        "    !tar xf \"dataperf_{lang}_data.tar.gz\""
      ],
      "metadata": {
        "id": "kktTuXtXdGpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will perform training set selection on the downloaded embeddings for each language, using our default selection algorithm (which simply performs crossfold-validation). The evaluation strategy can be changed by editing `dataperf-speech-example/workspace/dataperf_speech_config.yaml` \n",
        "\n",
        "The goal of this challenge is to add your own selection algorithm and outperform the provided baselines in both the minimal number of samples required and the final accuracy.\n",
        "\n",
        "The selection algorithm will output a training file for each language, `en_train.json`, `id_train.json`, and `pt_train.json`.\n",
        "\n",
        "These are the files you would upload to Dynabench for official evaluation, but in the next cell, we will run local unofficial evaluation using our provided evaluation data."
      ],
      "metadata": {
        "id": "wXWqcH_PfH_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in [\"en\", \"id\", \"pt\"]:\n",
        "    !cd dataperf-speech-example && \\\n",
        "        python -m selection.main \\\n",
        "        --language \"{lang}\" \\\n",
        "        --allowed_training_set \"/content/dataperf_{lang}_data/allowed_training_set.yaml\" \\\n",
        "        --train_embeddings_dir \"/content/dataperf_{lang}_data/train_embeddings/\" \\\n",
        "        --outdir \"/content/\""
      ],
      "metadata": {
        "id": "hWbNznXKdic7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's run a local unofficial evaluation on the results of the training set selection algorithm (`en_train.json`, `id_train.json`, and `pt_train.json`). \n",
        "\n",
        "For each language, a balanced accuracy score will be printed out, using the evaluation data samples specified in `eval.yaml`:\n",
        "\n",
        "```\n",
        "validating selected IDs\n",
        "loading selected training data\n",
        "Loading targets: 100% 5/5 [00:00<00:00, 25.49it/s]\n",
        "Loading nontargets: 100% 38/38 [00:00<00:00, 150.04it/s]\n",
        "loading eval data\n",
        "Loading targets: 100% 5/5 [00:00<00:00, 79.48it/s]\n",
        "Loading nontargets: 100% 200/200 [00:14<00:00, 14.13it/s]\n",
        "Score:  0.9174624016432674\n",
        "```\n"
      ],
      "metadata": {
        "id": "s9SoqEJGg-u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in [\"en\", \"id\", \"pt\"]:\n",
        "    !python dataperf-speech-example/eval.py \\\n",
        "      --language \"{lang}\" \\\n",
        "      --eval_embeddings_dir \"/content/dataperf_{lang}_data/eval_embeddings/\" \\\n",
        "      --train_embeddings_dir \"/content/dataperf_{lang}_data/train_embeddings/\" \\\n",
        "      --allowed_training_set \"/content/dataperf_{lang}_data/allowed_training_set.yaml\" \\\n",
        "      --eval_file \"/content/dataperf_{lang}_data/eval.yaml\" \\\n",
        "      --train_file \"/content/{lang}_train.json\" \\\n",
        "      --config_file dataperf-speech-example/workspace/dataperf_speech_config.yaml"
      ],
      "metadata": {
        "id": "6iwATQs1fGXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}